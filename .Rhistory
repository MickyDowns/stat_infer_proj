z = qnorm(1 - alpha) # yields 1.645 or num SD for 95th percentile
mu0=30    # this is the center of your population distribution
mua=32    # this is the mean of your sample
sigma=4   # this is your SD (or SE)
n=16      # observations
pnorm(mu0 + z * sigma/sqrt(n), mean = mu0, sd = sigma/sqrt(n), lower.tail = FALSE)
# technically, this give you the actual alpha which, where mean = mu0 is 0.05
pnorm(mu0 + z * sigma/sqrt(n), mean = mua, sd = sigma/sqrt(n), lower.tail = FALSE)
# this gives you the alpha (probability) if mean = mua is 0.6388
library(manipulate)
mu0=30
myplot = function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mu0,sd = sigma/sqrt(n)),
size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mua, sd = sigma/sqrt(n)),
size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha),
sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32),
n = slider(1, 50, step = 1, initial = 16),
alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
```
library(ggplot2)
myplot = function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mu0,sd = sigma/sqrt(n)),
size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mua, sd = sigma/sqrt(n)),
size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha),
sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32),
n = slider(1, 50, step = 1, initial = 16),
alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
mu0=30
myplot = function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mu0,sd = sigma/sqrt(n)),
size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line",
args = list(mean = mua, sd = sigma/sqrt(n)),
size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha),
sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32),
n = slider(1, 50, step = 1, initial = 16),
alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
t=power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
t
str(t)
?power.t.test
temp=power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
str(temp)
temp
power.t.test(n = 16, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$power
power.t.test(power = 0.8, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$n
set.seed(1010093)
pValues <- rep(NA, 1000)
for (i in 1:1000) {
y <- rnorm(20)
x <- rnorm(20)
pValues[i] <- summary(lm(y ~ x))$coeff[2, 4]
}
# Controls false positive rate
sum(pValues < 0.05)
x
y
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
# Controls FDR
sum(p.adjust(pValues, method = "BH") < 0.05)
set.seed(1010093)
pValues <- rep(NA, 1000)
for (i in 1:1000) {
x <- rnorm(20)
# First 500 beta=0, last 500 beta=2
if(i<=500){y <- rnorm(20) }else{y<-rnorm(20,mean=2*x) }
pValues[i] <- summary(lm(y ~ x))$coeff[2, 4] }
set.seed(1010093)
pValues <- rep(NA, 1000)
for (i in 1:1000) {
x <- rnorm(20)
# First 500 beta=0, last 500 beta=2
if(i<=500){y <- rnorm(20) }else{y<-rnorm(20,mean=2*x) }
pValues[i] <- summary(lm(y ~ x))$coeff[2, 4] }
trueStatus <- rep(c("zero", "not zero"), each = 500)
table(pValues < 0.05, trueStatus)
table(p.adjust(pValues, method = "bonferroni") < 0.05, trueStatus)
# Controls FDR
table(p.adjust(pValues, method = "BH") < 0.05, trueStatus)
24/500
13/500
par(mfrow = c(1, 2))
plot(pValues, p.adjust(pValues, method = "bonferroni"), pch = 19) plot(pValues, p.adjust(pValues, method = "BH"), pch = 19)
par(mfrow = c(1, 2))
plot(pValues, p.adjust(pValues, method = "bonferroni"), pch = 19)
plot(pValues, p.adjust(pValues, method = "BH"), pch = 19)
libarary(UsingR)
data(father.son)
x=father.son$sheight
n=length(x)
B=10000
?father.con
library(UsingR)
data(father.son)
x=father.son$sheight
n=length(x)
B=10000
# generate 10,000 samples of length n from from the son's height column
# replace=TRUE makes an "emperical distribution" (distribution where prob of any given sample is 1/n)
resamples=matrix(sample(x,n*B,replace=TRUE),B,n)
# then find median of all 10,000 samples
resampledMedians=apply(resamples,1,median)
hist(resampledMedians)
par(mfrow=c(1,1))
hist(resampledMedians)
B=10000
resamples=matrix(sample(x,n*B,replace=TRUE),B,n)
medians=applhy(resamples,1,median)
medians=apply(resamples,1,median)
sd(medians)
quantile(medians, c(0.025,0.975))
g=ggplot(data.frame(medians=medians),aes(x=medians))
g=g+geom_histogram(color="black",fill="red",binwidth=0.05)
g
data(InsectSprays)
boxplot(count~spray, data=InsectSprays)
subdata=InsectSprays[InsectSprays$spray %in% c("B","C"),]
y=subdata$count
y
lenth(subdata)
group=as.character(subdata$spray)
group
testStat=function(w,g) mean(w[g=="B"])-mean(w[g=="C"])
testStat
# take out only observations w/ spray == B or C
subdata=InsectSprays[InsectSprays$spray %in% c("B","C"),]
# get the count for remaining records
y=subdata$count
# get the spray for remaining records
group=as.character(subdata$spray)
# make a function to calculate your statistic of interest: the difference of the means for each group
testStat=function(w,g) mean(w[g=="B"])-mean(w[g=="C"])
# call the function to generate your statisitc passing your counts (y) and sprays (group)
observedStat=testStat(y,group)
# run your permutations by sampling from the the spary variable (group), grabbing the corresponding y, calculating the mean difference... 10,000 times.
permutations=sapply(1:10000,function(i) testStat(y,sample(group)))
# return the observed statistic
observedStat
mean(permutations>observedStat)
hist(permutations)
hist(permutations,col="lightblue")
abline(v,observedStat)
?hist
hist(permutations,xlim=c(-10,15),col="lightblue")
abline(v,observedStat)
?abline
hist(permutations,xlim=c(-10,15),col="lightblue")
abline(v=observedStat)
abline(v=observedStat,col="red",lwd=4)
hist(permutations,xlim=c(-10,15),binwidth=2,col="lightblue")
hist(permutations,xlim=c(-10,15),bin=2,col="lightblue")
?hist
hist(permutations,xlim=c(-10,15),breaks=2,col="lightblue")
hist(permutations,xlim=c(-10,15),breaks=100,col="lightblue")
hist(permutations,xlim=c(-10,15),breaks=50,col="lightblue")
abline(v=observedStat,col="red",lwd=4)
base=c(140,138,150,148,135)
wk2=c(132,135,151,146,130)
differnce=(mean(wk2)-mean(base))
difference=(mean(wk2)-mean(base))
s=sd(difference)
n=5
difference+c(-1,1)*qt(0.975,n-1)*s/sqrt(n)
difference
qt(0.975,4)
t.test(difference)
difference+c(-1,1)
qt(0.975,n-1)
difference+c(-1,1)*qt(0.975,n-1)
s/sqrt(n)
sd(difference)
difference
difference=base-wk2
s=sd(difference)
n=5
difference+c(-1,1)*qt(0.975,n-1)*s/sqrt(n)
t.test(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1)*s/sqrt(n)
mn=1100
s=30
n=9
mn+c(-1,1)*qt(0.975,n-1,two.sided=TRUE)*s/sqrt(n)
mn+c(-1,1)*qt(0.975,n-1,one.sided=FALSE)*s/sqrt(n)
?qt
mn+c(-1,1)*qt(0.975,n-1,lower.tail=TRUE)*s/sqrt(n)
n=4
p=(1,0,0,0)
c=(0,1,1,1)
p=c(1,0,0,0)
c=c(0,1,1,1)
difference=c-p
difference
t.test(difference)
?t.test
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
difference=c-p
n=4
p=c(1,0,0,0)
c=c(0,1,1,1)
s=sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference)
t.test(difference,alternative="greater")
difference=c
s=sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference,alternative="greater")
t.test(difference,alternative="two.sided")
difference
sd
sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
n=4
p=c(1,0,0,0)
c=c(0,1,1,1)
difference=c-p
s=sd(difference)
s
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference,alternative="two.sided")
t.test(difference,alternative="greater")
t.test(difference,alternative="greater")/2
t.test(difference,alternative="greater")$p-value
res=t.test(difference,alternative="greater")
str(res)
t.test(difference,alternative="greater")$p.value/2
10/1787
1/100
mua=10/1787
mu=1/100
ha=10/1787
h0=1/100
lambda=1/100
ppois(mua,mu0,lower.tail=F)
ppois(mua,mu0,lower.tail=T)
mua
mu0
mu0=1/100
mua=10/1787
lambda=1/100
ppois(mua,mu0,lower.tail=T)
ppois(mua,mu0,lower.tail=F)
mua
mu0
ppois(mu0,mua,lower.tail=F)
ppois(mu0,mua,lower.tail=T)
1-ppois(mu0,mua,lower.tail=T)
10/1787
(10/1787)*100
ppois(0.56,1,lower.tail=T)
ppois(0.56,1,lower.tail=F)
(10/1787)*100
ppois(6,10,lower.tail=F)
ppois(4,10,lower.tail=F)
ppois(6,10,lower.tail=T)
ppois(5,10,lower.tail=T)
10/1787
ppois(6,10,lower.tail=T)
ppois(0.56,1,lower.tail=T)
ppois(0.6,1,lower.tail=T) # yields 0.37
ppois(6,10,lower.tail=T) # yields
ppois(56,100,lower.tail=T)
ppois(56,100,lower.tail=F)
ppois(5.6,10,lower.tail=T)
?ppois
ppois(56,100,lower.tail=T)
ppois(56,100,lower.tail=F) # yields 0.
ppois(56,100,lower.tail=T) # yields 0.
ppois(5.7,10,lower.tail=T) # yields 0.07
n=8
p=c(1,0,0,0)
c=c(0,1,1,1)
difference=c-p
s=sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference,alternative="greater")$p.value/2
n=18
mn.diff.tr=-3
mn.diff.pl=1
sd.mn.diff=1.5
sd.mn.diff.tr=1.5
sd.mn.diff.pl=1.8
n=100
mua=0.01
s=0.04
alpha=0.05
z=qnorm(1-alpha)
pnorm(0+z*s/sqrt(n),mean=mua,sd=s/sqrt(n),lower.tail=FALSE)
power.t.test(n=100,delta=(0-mua),sd=s,type="one.sample",alt="one.sided")$power
n=100
mua=0.01
s=0.04
alpha=0.05
z=qnorm(1-alpha)
pnorm(0+z*s/sqrt(n),mean=mua,sd=s/sqrt(n),lower.tail=FALSE)
power.t.test(n=100,delta=(mua-0),sd=s,type="one.sample",alt="one.sided")$power
power.t.test(power=0.9,delta=(mua-0),sd=s,type="one.sample",alt="one.sided")$n
base=c(140,138,150,148,135)
wk2=c(132,135,151,146,130)
difference=base-wk2
s=sd(difference)
n=5
mean(difference)+c(-1,1)*qt(0.975,n-1)*s/sqrt(n)
t.test(difference)
n=8
p=c(1,0,0,0)
c=c(0,1,1,1)
difference=c-p
s=sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference,alternative="greater")$p.value
difference=c
s=sd(difference)
mean(difference)+c(-1,1)*qt(0.975,n-1,lower.tail=FALSE)*s/sqrt(n)
t.test(difference,alternative="greater")$p.value
ppois(6,10,lower.tail=F) # yields 0.13 guessed this one
ppois(5.7,10,lower.tail=T) # yields 0.07
ppois(5,10,lower.tail=T) # yields 0.13 guessed this one
ppois(56,100,lower.tail=T) # yields 0.
ppois(55,100,lower.tail=T) # yields 0.
?t.test
ppois(1/1787,1/100,lower.tail=T)
ppois(1/1787,1/100,lower.tail=F)
ppois(1/1787,1/100,lower.tail=F)
ppois((1/1787(*100),(1/100)*100,lower.tail=F)
ppois((1/1787)*100),(1/100)*100,lower.tail=F)
ppois((1/1787)*100,(1/100)*100,lower.tail=F)
ppois((1/1787)*1000,(1/100)*1000,lower.tail=F)
ppois((1/1787)*100,(1/100)*100,lower.tail=F)
(1/1787)*100
round((1/1787)*100,-2)
round((1/1787)*100,1)
round((1/1787)*100,2)
rounddown((1/1787)*100,2)
ppois(1/0.06,1/100,lower.tail=F)
ppois(1/0.06,1/100,lower.tail=F)
ppois((1/1787)*100,1/100,lower.tail=F)
ppois((1/1787)*100,(1/100)*100,lower.tail=F)
ymean=-3
xmean=1
difference=ymean-xmean
fact(10)
?factorial
factorial(10)
factorial(2)
factorial(8)
3600000/80000
2^30
1+30(30+1)/20
1+30*(30+1)/20
1+30*(30+1)/2
library(ISLR)
summary(Hitters)
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors),ylab="Root MSE",ylim=c(300,400),pch=19,type="b")
points(sqrt(regfit.fwd$rss[-1]/180),col="blue",pch=19,type="b")
legend("topright",legend=c("Training","Validation"),col=c("blue","black"),pch=19)
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
with(Hitters,sum(is.na(Salary)))
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors),ylab="Root MSE",ylim=c(300,400),pch=19,type="b")
points(sqrt(regfit.fwd$rss[-1]/180),col="blue",pch=19,type="b")
legend("topright",legend=c("Training","Validation"),col=c("blue","black"),pch=19)
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds=sample(rep(1:10,length=nrow(Hitters)))
folds
table(folds)
cv.errors=matrix(NA,10,19)
for(k in 1:10){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=k,],nvmax=19,method="forward")
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==k,],id=i)
cv.errors[k,i]=mean( (Hitters$Salary[folds==k]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
install.packages("glmnet")
library(glmnet)
x=model.matrix(Salary~.-1,data=Hitters)
y=Hitters$Salary
fit.ridge=glmnet(x,y,alpha=0)
plot(fit.ridge,xvar="lambda",label=TRUE)
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
plot(fit.ridge,xvar="lambda",label=TRUE)
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
fit.lasso=glmnet(x,y)
plot(fit.lasso,xvar="lambda",label=TRUE)
cv.lasso=cv.glmnet(x,y)
plot(cv.lasso)
coef(cv.lasso)
plot(fit.lasso,xvar="dev",label=TRUE)
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
pred=predict(lasso.tr,x[-train,])
dim(pred)
rmse= sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda),rmse,type="b",xlab="Log(lambda)")
lam.best=lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr,s=lam.best)
?cv.glimnet()
?cv.glmnet()
