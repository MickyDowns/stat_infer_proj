{
    "contents" : "---\ntitle: \"power\"\noutput: html_document\n---\n\n### calculating power manually\n```{r}\n\nalpha = 0.05 # this is the type I error rate. \nz = qnorm(1 - alpha) # yields 1.645 or num SD for 95th percentile\n\nmu0=30    # this is the center of your population distribution\nmua=32    # this is the mean of your sample \nsigma=4   # this is your SD (or SE)\nn=16      # observations\n\npnorm(mu0 + z * sigma/sqrt(n), mean = mu0, sd = sigma/sqrt(n), lower.tail = FALSE)\n# technically, this give you the actual alpha which, where mean = mu0 is 0.05 \n\npnorm(mu0 + z * sigma/sqrt(n), mean = mua, sd = sigma/sqrt(n), lower.tail = FALSE)\n# this gives you the alpha (probability) if mean = mua is 0.6388. so, you've got a 65% chance of getting a mean as large or larger than 32 w/ this experiment. \n```\n\n### using ggplot() and manipulate()\n```{r}\n# so, let's try to illustrate w/ manipulate\n\nlibrary(manipulate)\nlibrary(ggplot2)\n\nmua=32    # this is the mean of your sample \nsigma=4   # this is your SD (or SE)\nn=16      # observations\nmu0=30\nmyplot = function(sigma, mua, n, alpha) {\n     g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))\n     g = g + stat_function(fun = dnorm, geom = \"line\",\n                           args = list(mean = mu0,sd = sigma/sqrt(n)), \n                           size = 2, col = \"red\")\n     g = g + stat_function(fun = dnorm, geom = \"line\", \n                           args = list(mean = mua, sd = sigma/sqrt(n)), \n                           size = 2, col = \"blue\") \n     xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)\n     g = g + geom_vline(xintercept = xitc, size = 3)\n     g\n}\nmanipulate(myplot(sigma, mua, n, alpha), \n           sigma = slider(1, 10, step = 1, initial = 4),\n           mua = slider(30, 35, step = 1, initial = 32), \n           n = slider(1, 50, step = 1, initial = 16), \n           alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))\n```\n\n### using power.t.test()\n```{r}\n# solving for power\npower.t.test(n = 16, delta = 2/4, sd = 1, type = \"one.sample\", alt = \"one.sided\")$power\n\npower.t.test(n = 16, delta = 2, sd = 4, type = \"one.sample\", alt = \"one.sided\")$power\n\npower.t.test(n = 16, delta = 100, sd = 200, type = \"one.sample\", alt = \"one.sided\")$power\n\n# solving for n\npower.t.test(power = 0.8, delta = 100, sd = 200, type = \"one.sample\", alt = \"one.sided\")$n\n\n```\n\n### adjusting p-values\n```{r}\nset.seed(1010093) \npValues <- rep(NA, 1000) \nfor (i in 1:1000) {\n     y <- rnorm(20)\n     x <- rnorm(20)\n     pValues[i] <- summary(lm(y ~ x))$coeff[2, 4]\n}\n# Controls false positive rate\nsum(pValues < 0.05)\n# nets 51 p-values considered \"significant\" when really there's no relationship btwn x and y.\n\n# Controls FWER\nsum(p.adjust(pValues, method = \"bonferroni\") < 0.05)\n\n\n# Controls FDR\nsum(p.adjust(pValues, method = \"BH\") < 0.05)\n\n```\n\n### 50% true positives\n```{r}\n\nset.seed(1010093)\npValues <- rep(NA, 1000)\nfor (i in 1:1000) {\n     x <- rnorm(20)\n     # First 500 beta=0, last 500 beta=2 \n     if(i<=500){y <- rnorm(20) }else{y<-rnorm(20,mean=2*x) }\n     pValues[i] <- summary(lm(y ~ x))$coeff[2, 4] }\ntrueStatus <- rep(c(\"zero\", \"not zero\"), each = 500) \ntable(pValues < 0.05, trueStatus)\n\n# Controls FWER\ntable(p.adjust(pValues, method = \"bonferroni\") < 0.05, trueStatus)\n# Controls FDR\ntable(p.adjust(pValues, method = \"BH\") < 0.05, trueStatus)\n\n# graphing the results\npar(mfrow = c(1, 2))\nplot(pValues, p.adjust(pValues, method = \"bonferroni\"), pch = 19) \nplot(pValues, p.adjust(pValues, method = \"BH\"), pch = 19)\n```",
    "created" : 1422664871030.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "664743748",
    "id" : "5E88EC5D",
    "lastKnownWriteTime" : 1422815267,
    "path" : "~/Documents/Pers/Ed/Courses/JH5 - statistical inference/stat_infer_proj/power.Rmd",
    "project_path" : "power.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}